{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f146af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745bdd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "def timed_memory_profile(func, *args, **kwargs):\n",
    "    tracemalloc.start()\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    result = func(*args, **kwargs)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print(f\"Execution time: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Current memory usage: {current / 1024:.2f} KB\")\n",
    "    print(f\"Peak memory usage: {peak / 1024:.2f} KB\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f6504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from app.services import (\n",
    "    extract_top_n_nouns_with_frequency,\n",
    "    get_sentences_with_target_word\n",
    ")\n",
    "\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "ALL_NOUNS = {lemma.name().lower() for synset in wn.all_synsets(wn.NOUN) for lemma in synset.lemmas()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad81e769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873235\n"
     ]
    }
   ],
   "source": [
    "with open('../static/uploads/psychology_explained.txt') as f:\n",
    "    text_content = f.read()\n",
    "\n",
    "print(len(text_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dadfd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'psychology': 621,\n",
       " 'people': 338,\n",
       " 'behavior': 316,\n",
       " 'memory': 290,\n",
       " 'theory': 254,\n",
       " 'approach': 218,\n",
       " 'personality': 215,\n",
       " 'world': 211,\n",
       " 'freud': 186,\n",
       " 'intelligence': 185}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_top_n_nouns_with_frequency(text_content, 10, STOP_WORDS, ALL_NOUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fc558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated sentence to 485 tokens: 54 dementia 31 depression 109, 140, 142, 154, 159, 176, 200, 201, 243 Depression: Causes and Treatme...\n"
     ]
    }
   ],
   "source": [
    "sentences = get_sentences_with_target_word(text_content, 'psychology', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5fc9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d38d57d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the psychology book the psychology book dk london project art editor amy orsborne senior editors sam atkinson sarah tomley editors cecile landau scarlett hara us editor rebecca warren managing art editor karen self managing editors esther ripley camilla hallinan art director philip ormerod associate publishing director liz wheeler publishing director jonathan metcalf illustrations james graham picture research myriam megharbi production editor tony phipps production controller angela graef dk delhi project art editor shruti soharia singh senior art editor chhaya sajwan managing art editor arunesh talapatra senior editor monica saigal editorial team sreshtha bhattacharya gaurav joshi production manager pankaj sharma dtp manager cts balwant singh dtp designers arvind kumar rajesh singh adhikari dtp operator vishal bhatia styling by studio design dk books are available at special discounts when purchased in bulk for sales promotions premiums fund raising or educational use',\n",
       " 'nigel benson lecturer in philosophy and psychology nigel benson has written several bestselling books on the subject of psychology including psychology for beginners and introducing psychiatry',\n",
       " 'joannah ginsburg clinical psychologist and journalist joannah ginsburg works in community treatment centers in new york city boston philadelphia and dallas and regularly contributes to psychology publications',\n",
       " 'she is joint author of this book has issues adventures in popular psychology']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656830c4",
   "metadata": {},
   "source": [
    "# Testing the Disamb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b42d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from app.services import get_sentences_with_target_word\n",
    "from app.models import DisambModel  # or adjust import as per your structure\n",
    "\n",
    "# Load model & tokenizer\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DisambModel(bert_model, bert_tokenizer, device)\n",
    "\n",
    "# Example input\n",
    "text = \"Psychology is the study of the mind. Cognitive psychology explores thought. Psychology is fascinating.\"\n",
    "target_word = \"psychology\"\n",
    "sentences = get_sentences_with_target_word(text, target_word)\n",
    "\n",
    "sentence_embeddings = []\n",
    "for sent in sentences:\n",
    "    try:\n",
    "        emb = model.forward(sent, target_word)\n",
    "        sentence_embeddings.append(emb)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping: {sent[:50]} â€” {e}\")\n",
    "\n",
    "# (Optional) Stack for vector ops\n",
    "if sentence_embeddings:\n",
    "    embedding_matrix = torch.stack(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff209721",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.stack(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75257ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66d225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target embedding shape: torch.Size([768])\n",
      "Sentence embedding shape: torch.Size([768])\n",
      "Number of token embeddings: 9\n",
      "Top similar context words: [('the', 0.6852102279663086), ('is', 0.5861321091651917), ('near', 0.5287748575210571), ('the', 0.5086743831634521), ('river', 0.502588152885437), ('.', 0.06643393635749817)]\n"
     ]
    }
   ],
   "source": [
    "# Get target word embedding\n",
    "vec = model.forward(\"The bank is near the river.\", \"bank\")\n",
    "\n",
    "# Get sentence embedding\n",
    "sent_vec = model.get_sentence_embedding(\"The bank is near the river.\")\n",
    "\n",
    "# Get all token embeddings\n",
    "token_vecs = model.get_all_token_vectors(\"The bank is near the river.\")\n",
    "\n",
    "# Get most similar tokens to target\n",
    "sim_words = model.get_context_words(\"The bank is near the river.\", \"bank\")\n",
    "\n",
    "# Print results (optional)\n",
    "print(\"Target embedding shape:\", vec.shape)\n",
    "print(\"Sentence embedding shape:\", sent_vec.shape)\n",
    "print(\"Number of token embeddings:\", len(token_vecs))\n",
    "print(\"Top similar context words:\", sim_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
